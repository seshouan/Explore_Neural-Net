{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db54ff-1f0e-4cc0-afd5-9772298b4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9e8ac-dbb7-46eb-9059-c3079d753650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layer_dims):\n",
    "    \"\"\"\n",
    "    initialize layer parameters weights and biases\n",
    "    \n",
    "    inputs\n",
    "        layer_dims: matrix with the dimensions of each layer\n",
    "    output\n",
    "        params: dictionary of layer weights and biases\n",
    "    \"\"\"\n",
    "    \n",
    "    # declare variables\n",
    "    np.random.seed(3)\n",
    "    params = {}\n",
    "    \n",
    "    # initialize the weight and bias parameters for each layer\n",
    "    for l in range(1 to len(layer_dims)):\n",
    "        params['W'+str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        params['b'+str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    \n",
    "    # return output\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74e344-e609-44a4-b6b9-bb59dba87fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    apply the sigmoid formula to the provided layer\n",
    "    \n",
    "    inputs\n",
    "        Z: neural net layer\n",
    "    output\n",
    "        A: activation of layer Z with sigmoid\n",
    "        cache: stored value of Z for backprop\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the activation\n",
    "    A = 1 / (1 + np.exp(np.dot(-1, Z)))\n",
    "    \n",
    "    # save layer\n",
    "    cache = (Z)\n",
    "    \n",
    "    # return output\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6791649-2345-47f0-8e1d-0405e828af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, params):\n",
    "    \"\"\"\n",
    "    generate node computations from the input of a shalower layer, activate the layer, and feed its output to a deeper layer\n",
    "    \n",
    "    inputs\n",
    "        X: input layer matrix\n",
    "        params: dictionary of layer weights and biases\n",
    "    output\n",
    "        A: last activation function into the output layer\n",
    "        caches: stored values of each layer computation Z for backprop\n",
    "    \"\"\"\n",
    "    \n",
    "    # declare variables\n",
    "    A = X # the first activation is set to the input layer matrix\n",
    "    caches = []\n",
    "    \n",
    "    # propagate the activations forward through each layer\n",
    "    for l in range(1 to ((params // 2) + 1)):\n",
    "        # retain the previous activation\n",
    "        A_prev = A\n",
    "        \n",
    "        # perform the current layer computation Z\n",
    "        Z = np.dot(params['W'+str(l)], A_prev) + params['b'+str(l)]\n",
    "        \n",
    "        # capture the linear cache\n",
    "        linear_cache = (A_prev, params['W'+str(l)], params['b'+str(l)])\n",
    "        \n",
    "        # apply the activation function on on the current layer computation\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "        # store the linear and activation caches\n",
    "        caches.append((linear_cache, activation_cache))\n",
    "    \n",
    "    # return output\n",
    "    return A, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b17d9-0fc5-4c2b-82f7-6eeb2944467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(A, Y):\n",
    "    \"\"\"\n",
    "    generate the cost function of the output of the model\n",
    "    \n",
    "    inputs\n",
    "        A: last activation function into the output layer\n",
    "        Y: matrix of predicted outputs\n",
    "    output\n",
    "        cost: resulting cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the slope variable for the cost function\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    # compute the cost function\n",
    "    cost = (-1/m) * np.dot(np.log(A), Y.T) + np.dot(np.log(1-A), 1-Y.T)\n",
    "    \n",
    "    # return output\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f339e-ac08-46af-a082-bb6a223408f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
